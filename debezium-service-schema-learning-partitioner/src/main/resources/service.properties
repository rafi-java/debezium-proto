# Job
job.factory.class=org.debezium.samza.SliceJobFactory
job.name=schema-learning-partitioner-service
job.id=1
job.systemstreampartition.grouper.factory=org.debezium.samza.GroupByPartitionRangeFactory
job.partition.range=ALL
job.threads=1

# Task
task.class=org.debezium.services.EntityBatchService
task.inputs=kafka.schema-updates,kafka.entity-updates

# Declare that we want our job's checkpoints to be written to Kafka
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.system=kafka
task.checkpoint.replication.factor=1
task.checkpoint.segment.bytes=26214400

# By default, a checkpoint is written every 60 seconds. You can change this if you like.
task.commit.ms=60000

# Serializers
serializers.registry.document.class=org.debezium.core.serde.DocumentSerdeFactory
serializers.registry.string.class=org.debezium.core.serde.StringSerdeFactory

# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.key.serde=string
systems.kafka.samza.msg.serde=document
systems.kafka.consumer.zookeeper.connect=zookeeper:2181/
systems.kafka.consumer.auto.offset.reset=largest
systems.kafka.producer.bootstrap.servers=kafka:9092
