# Job
job.factory.class=org.debezium.samza.SliceJobFactory
job.name=schema-storage-service
job.id=1
job.systemstreampartition.grouper.factory=org.debezium.samza.GroupByPartitionRangeFactory
job.partition.range=ALL
job.threads=1

# Task
task.class=org.debezium.service.SchemaStorageService
task.inputs=kafka.schema-patches

# Declare that we want our job's checkpoints to be written to Kafka
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.system=kafka
task.checkpoint.replication.factor=1
task.checkpoint.segment.bytes=26214400

# By default, a checkpoint is written every 60 seconds. You can change this if you like.
task.commit.ms=60000

# Serializers
serializers.registry.document.class=org.debezium.core.serde.DocumentSerdeFactory
serializers.registry.string.class=org.debezium.core.serde.StringSerdeFactory

# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.key.serde=string
systems.kafka.samza.msg.serde=document
systems.kafka.consumer.zookeeper.connect=zookeeper:2181/
systems.kafka.consumer.auto.offset.reset=largest
systems.kafka.producer.bootstrap.servers=kafka:9092

# Key-value storage
stores.schema-store.factory=org.apache.samza.storage.kv.RocksDbKeyValueStorageEngineFactory
stores.schema-store.changelog=kafka.schema-store-changelog
stores.schema-store.key.serde=string
stores.schema-store.msg.serde=document
stores.schema-store.changelog.replication.factor=1

# Normally, we'd set this much higher, but we want things to look snappy in the demo.
stores.schema-store.write.batch.size=0
stores.schema-store.object.cache.size=0

# Service properties
